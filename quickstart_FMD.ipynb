{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67afb4f0-59e5-42d5-8cd1-5426ac8f73ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from skimage.metrics import structural_similarity\n",
    "from torch.nn import MSELoss\n",
    "mse_loss = MSELoss(size_average = True)\n",
    "\n",
    "from basicsr.models import create_model, load_finetuned_model\n",
    "from basicsr.utils import img2tensor as _img2tensor, tensor2img, imwrite\n",
    "from basicsr.models.image_restoration_model import ImageRestorationModel\n",
    "from basicsr.utils.options import parse\n",
    "\n",
    "from tqdm.notebook import tqdm as log_progress\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c09ee-1e6c-43cd-b247-0b76c26bfc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af29dc57-ba6b-41ab-b7e8-f49f1e4c8c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in our finetuned weights to the NAFNet model\n",
    "finetuned_weight_path = 'finetuned_weights.pth'\n",
    "config_path = 'model_config.yml'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "finetuned = load_finetuned_model(finetuned_weight_path, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7710236b-3c81-4a8a-837b-4e553496edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading different samples from the MPM Dataset\n",
    "samp_name = [\"conf_F\", \"conf_M\", \"conf_R\", \"twop_B\", \"twop_G\", \"twop_M\", \"twop_R\"]\n",
    "\n",
    "gt_dict = np.load('quickstart_samples/FMD_samples_gt.npy',allow_pickle='TRUE').item()\n",
    "noisy_dict = np.load('quickstart_samples/FMD_samples_noisy.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628e7705-4ace-4375-a860-0f7a4810a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predetermined Lhat values to ensure statistical coverage on the intervals\n",
    "lhat = [2.1643288, 2.204409,  2.3647294, 2.284569, 2.3647294, 1.6232464, 2.204409, 2.224449, 2.1843688, 2.1643288, 2.1242485, 2.0440881, 2.024048, 1.9839679, 1.9639279, 1.8036072, 1.763527, 1.7234468,1.7034068,1.4428858  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a346dfab-38c9-4d4a-8eea-8472c6076f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "test_ssim = []\n",
    "\n",
    "denoised_dict = {}\n",
    "uncertain_dict = {}\n",
    "mse_dict = {}\n",
    "ssim_dict = {}\n",
    "\n",
    "for key, single_image in noisy_dict.items():\n",
    "    single_gt = gt_dict[key]\n",
    "    uncertainties, multi_predictions, mses, ssim_vals = [], [], [], []\n",
    "    single_gt = [gt for gt in single_gt] \n",
    "    \n",
    "    for i, in_img in enumerate(single_image):\n",
    "        in_img = in_img.unsqueeze(0).to(device)  # (1, 5, 512, 512)\n",
    "\n",
    "        out = finetuned(in_img.float())  # (1, 5, 3, 512, 512)\n",
    "\n",
    "        # Extract prediction and uncertainty bounds\n",
    "        upper = out[0, 2, :, :].detach().cpu()\n",
    "        pred = out[0, 1, :, :].detach().cpu()\n",
    "        lower = out[0, 0, :, :].detach().cpu()\n",
    "\n",
    "        pred /= torch.max(pred)  # Normalize prediction\n",
    "        multi_predictions.append(pred)\n",
    "\n",
    "        # Compute uncertainty\n",
    "        uncertainty = ((upper - lower) * lhat[i]).cpu().numpy()\n",
    "        uncertainties.append(uncertainty)\n",
    "\n",
    "        # Compute MSE and SSIM\n",
    "        err = mse_loss(pred.float(), single_gt[i])\n",
    "        mses.append(err)\n",
    "        ssim_vals.append(structural_similarity(pred.numpy(), single_gt[i][0, :,:].numpy()))\n",
    "\n",
    "    # Store results in dictionaries\n",
    "    denoised_dict[key] = multi_predictions\n",
    "    uncertain_dict[key] = uncertainties\n",
    "    mse_dict[key] = mses\n",
    "    ssim_dict[key] = ssim_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d5576-c671-4b88-af91-a386ab220dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at Uncertainty Trends for an FMD Sample\n",
    "sample = \"twop_G\"\n",
    "\n",
    "denoised_sample = denoised_dict[sample]\n",
    "uncertainty_sample = uncertain_dict[sample]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6)) \n",
    "x = 150\n",
    "y = 130\n",
    "for i in range(4):\n",
    "    axes[0, i].imshow(denoised_sample[i * 5][x:x + 125, y: y + 125], cmap = \"gray\")  \n",
    "    axes[0, i].axis(\"off\") \n",
    "    axes[0, i].set_title(f\"Iteration {i * 5}\")\n",
    "\n",
    "for i in range(4):\n",
    "    axes[1, i].imshow(uncertainty_sample[i * 5][x:x + 125,y: y + 125], cmap=\"rainbow\", vmax = np.max(uncertainty_sample[15]))  \n",
    "    axes[1, i].axis(\"off\")  \n",
    "    axes[1, i].set_title(f\"Iteration {i * 5}\")\n",
    "\n",
    "\n",
    "fig.text(0.0, 0.75, \"Denoised\", va=\"center\", ha=\"center\", fontsize=14, rotation=90)\n",
    "fig.text(0.0, 0.25, \"Uncertainty\", va=\"center\", ha=\"center\", fontsize=14, rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e441292c-17ce-4f3c-8f33-6ee519ea2127",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_pix_scanned = 512 * 512 * 20\n",
    "\n",
    "# ADAPTIVE PART\n",
    "gt_name = \"conf_M\"\n",
    "noisy_ims_torch = noisy_dict[gt_name][-1]\n",
    "\n",
    "x, y = 80, 300\n",
    "percents = list(range(90, 100, 1))\n",
    "\n",
    "adaptive_dict = {}\n",
    "uncertainty_dict = {}\n",
    "mse_error_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for percent in log_progress(percents):\n",
    "        adaptive_images = []\n",
    "        uncertainty_perc = []\n",
    "        num_pixels_scanned = []\n",
    "\n",
    "        # Prepare input image batch\n",
    "        noisy_0 = noisy_ims_torch[0]\n",
    "        in_img = noisy_0.repeat(20, 1, 1).unsqueeze(0).to(device)\n",
    "\n",
    "        # Initial model inference\n",
    "        out = finetuned(in_img.float())[0].detach().cpu()\n",
    "        uncertainty_0 = torch.clamp((out[2] - out[0]) * lhat[-1], 0, 1)\n",
    "\n",
    "        num_pixels_scanned.append(in_img.shape[-1] ** 2)\n",
    "        unc_thresh = np.percentile(uncertainty_0, percent)\n",
    "        \n",
    "        for i in range(1, 20):\n",
    "            mask = uncertainty_0 >= unc_thresh\n",
    "            noisy_now = torch.where(mask, noisy_ims_torch[i], noisy_0)\n",
    "            num_pixels_scanned.append(mask.sum().item())\n",
    "\n",
    "            in_img[0, i] = noisy_now.to(device)\n",
    "\n",
    "            out = finetuned(in_img.float())[0].detach().cpu()\n",
    "            adaptive_images.append(out[1].clone())\n",
    "\n",
    "            uncertainty_0 = (out[2] - out[0]) * lhat[-1]\n",
    "            uncertainty_perc.append(uncertainty_0.clone())\n",
    "\n",
    "        perc_pix_rescanned = sum(num_pixels_scanned) / tot_pix_scanned\n",
    "        adaptive_dict[percent] = adaptive_images\n",
    "        uncertainty_dict[percent] = uncertainty_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122fa066-0858-4c84-8db9-a59d43fff256",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_perc = adaptive_dict[99]\n",
    "uncertainty_perc = uncertainty_dict[99]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6)) \n",
    "x = 0\n",
    "y = 250\n",
    "for i in range(4):\n",
    "    axes[0, i].imshow(adaptive_perc[i * 5][x:x + 125, y: y + 125], cmap = \"gray\")  \n",
    "    axes[0, i].axis(\"off\") \n",
    "    axes[0, i].set_title(f\"Iteration {i * 5}\")\n",
    "\n",
    "for i in range(4):\n",
    "    axes[1, i].imshow(uncertainty_perc[i * 5][x:x + 125,y: y + 125], cmap=\"rainbow\", vmax = torch.max(uncertainty_perc[0]))  \n",
    "    axes[1, i].axis(\"off\")  \n",
    "    axes[1, i].set_title(f\"Iteration {i * 5}\")\n",
    "\n",
    "fig.text(0.0, 0.75, \"Adaptively Denoised (6%)\", va=\"center\", ha=\"center\", fontsize=14, rotation=90)\n",
    "fig.text(0.0, 0.25, \"Uncertainty\", va=\"center\", ha=\"center\", fontsize=14, rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-test]",
   "language": "python",
   "name": "conda-env-.conda-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
